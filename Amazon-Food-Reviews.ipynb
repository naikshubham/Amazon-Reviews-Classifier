{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piLO92Y7xwgy"
   },
   "source": [
    "# Amazon Food Reviews - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AHKfM81x77Z"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q PyDrive\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "# json_import = drive.CreateFile({'id':'1KpQKJnoX3XCpyW788srGxtO3nwZFJ4oE'})\n",
    "# json_import.GetContentFile('database.sqlite')\n",
    "# json_import = drive.CreateFile({'id':'1XRPgjWYDhIllbS4VWLGDIJ8-pcP7A_r4'})\n",
    "# json_import.GetContentFile('final.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23916,
     "status": "ok",
     "timestamp": 1569578165141,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "WzZo0tRRxwgz",
    "outputId": "48a27985-de2f-4637-b79c-5b210b5cb44e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shubham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M79VbrTLxwg5"
   },
   "outputs": [],
   "source": [
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('./final.sqlite') \n",
    "\n",
    "\n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26274,
     "status": "ok",
     "timestamp": 1569578167560,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "yzVwngWgzVqx",
    "outputId": "4967dc10-c8b9-4da1-ea84-ec20e2c6ef96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138688</td>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>b'grew read sendak book watch realli rosi movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138689</td>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>b'fun way children learn month year learn poem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138690</td>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>b'great littl book read nice rhythm well good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138691</td>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>b'book poetri month year goe month cute littl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      Id   ProductId          UserId                  ProfileName  \\\n",
       "0  138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "1  138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "2  138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "3  138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "4  138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     0                       0  positive   939340800   \n",
       "1                     1                       1  positive  1194739200   \n",
       "2                     1                       1  positive  1191456000   \n",
       "3                     1                       1  positive  1076025600   \n",
       "4                     3                       4  positive  1018396800   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                   EVERY book is educational   \n",
       "1  Love the book, miss the hard cover version   \n",
       "2               chicken soup with rice months   \n",
       "3      a good swingy rhythm for reading aloud   \n",
       "4             A great way to learn the months   \n",
       "\n",
       "                                                Text  \\\n",
       "0  this witty little book makes my son laugh at l...   \n",
       "1  I grew up reading these Sendak books, and watc...   \n",
       "2  This is a fun way for children to learn their ...   \n",
       "3  This is a great little book to read aloud- it ...   \n",
       "4  This is a book of poetry about the months of t...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'witti littl book make son laugh loud recit c...  \n",
       "1  b'grew read sendak book watch realli rosi movi...  \n",
       "2  b'fun way children learn month year learn poem...  \n",
       "3  b'great littl book read nice rhythm well good ...  \n",
       "4  b'book poetri month year goe month cute littl ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxyU7Qzqxwg7"
   },
   "outputs": [],
   "source": [
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "# def partition(x):\n",
    "#     if x < 3:\n",
    "#         return 'negative'\n",
    "#     return 'positive'\n",
    "def give_scores(score):\n",
    "    score = np.asarray(score)\n",
    "    score = np.where(score == 'positive', 1, 0)\n",
    "    return score\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "# positiveNegative = actualScore.map(partition) \n",
    "positiveNegative = give_scores(actualScore)\n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26232,
     "status": "ok",
     "timestamp": 1569578167562,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "sFJiNVXA2RVy",
    "outputId": "5c2d3eb5-ff19-47a3-ecb0-f579a3cf7e77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    307061\n",
       "0     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXpPI36hxwg-"
   },
   "outputs": [],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIrDgDy3xwhB"
   },
   "source": [
    "## Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28166,
     "status": "ok",
     "timestamp": 1569578169519,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "8eDbowjCxwhB",
    "outputId": "cf6c9a4b-2d10-4de1-e36b-424bba5db013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "# find sentences containing HTML tags\n",
    "# i=0;\n",
    "# for sent in final['Text'].values:\n",
    "#     if (len(re.findall('<.*?>', sent))):\n",
    "# #         print(i)\n",
    "# #         print(sent)\n",
    "#         break\n",
    "#     i += 1\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "print(len(stop))\n",
    "stop.remove('not')\n",
    "print(len(stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd4sDqvYxwhE"
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "stop.remove('not')\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qpbc2bo3xwhG"
   },
   "outputs": [],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 1: #'positive': \n",
    "                        all_positive_words.append(s)    #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 0:  #'negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nywzc7ijxwhJ"
   },
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujV-3wy8xwhL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# store final table into an SQlLite table for future.\n",
    "# conn = sqlite3.connect('final.sqlite')\n",
    "# c=conn.cursor()\n",
    "# conn.text_factory = str\n",
    "# final.to_sql('Reviews', conn, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0KPmlFRxwhO"
   },
   "source": [
    "## Converting AFR data into IMDB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 325104,
     "status": "ok",
     "timestamp": 1569578466498,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "mLpb5GdSxwhP",
    "outputId": "b68238b5-6ad9-41b3-f9fe-8ad9cb428700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    307061\n",
       "0     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Y4yUZiYxwhS"
   },
   "source": [
    "### As dataset is imbalanced, sampled equal datapoints for both the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 326388,
     "status": "ok",
     "timestamp": 1569578467794,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "v29p09YqxwhT",
    "outputId": "2d9e7163-e58c-449b-ee63-e94979cdffdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113446</th>\n",
       "      <td>Received my package today and I was not please...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73475</th>\n",
       "      <td>Used it to color on white chocolate candy, col...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92132</th>\n",
       "      <td>The initial link states 12 - 20oz bottles, but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46159</th>\n",
       "      <td>Imagine if you will a 1st grader in 1965.&lt;br /...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31976</th>\n",
       "      <td>Just what we wanted, loose rooibos tea.  Green...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score\n",
       "113446  Received my package today and I was not please...      0\n",
       "73475   Used it to color on white chocolate candy, col...      0\n",
       "92132   The initial link states 12 - 20oz bottles, but...      0\n",
       "46159   Imagine if you will a 1st grader in 1965.<br /...      1\n",
       "31976   Just what we wanted, loose rooibos tea.  Green...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling equal datapoints\n",
    "final = shuffle(final)\n",
    "final_balanced_reviews = final.loc[final['Score'] == 1][:57000]\n",
    "neg_reviews = final.loc[final['Score'] == 0][:57000]\n",
    "final_balanced_reviews = final_balanced_reviews.append(neg_reviews, ignore_index=True)\n",
    "final_balanced_reviews = final_balanced_reviews[['Text', 'Score']]\n",
    "final_balanced_reviews = shuffle(final_balanced_reviews)\n",
    "final_balanced_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 326373,
     "status": "ok",
     "timestamp": 1569578467799,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "zsx3ydxjxwhZ",
    "outputId": "c16ad8c7-a861-44e7-ae50-03009ef6809d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57000\n",
       "0    57000\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_balanced_reviews['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWqP1fUi9gLd"
   },
   "source": [
    "## TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 277373,
     "status": "ok",
     "timestamp": 1569578473370,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "g3GbWQAx9jZ4",
    "outputId": "6dc1fe07-8d47-490e-a9c5-58b39c2b4d6f"
   },
   "outputs": [],
   "source": [
    "X = final_balanced_reviews['Text']\n",
    "Y = np.array(final_balanced_reviews['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6vVMHL4MacR"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1569579330919,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "6QE6RUINNNWh",
    "outputId": "b735fce9-c47b-472b-8135-3b8d47fcf558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size -> (72960,) (72960,)\n",
      "test size -> (22800,) (22800,)\n",
      "validation size -> (18240,) (18240,)\n"
     ]
    }
   ],
   "source": [
    "print('train size ->', X_train.shape, Y_train.shape)\n",
    "print('test size ->', X_test.shape, Y_test.shape)\n",
    "print('validation size ->', X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF featurization after train test split to avoid Data leakage problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.fit_transform(X_val)\n",
    "print(type(X))\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Best Hyperparameter search using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimators -> LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "SCore -> 0.8938323160938001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "tuned_parameters = [{'C' : [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "\n",
    "# Using GridSearchCV\n",
    "model = GridSearchCV(LogisticRegression(), tuned_parameters, scoring='f1', cv=5)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Best estimators ->', model.best_estimator_)\n",
    "X_test = vectorizer.fit_transform(X_test)\n",
    "print('SCore ->', model.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJtQHfQkBoq5"
   },
   "source": [
    "### Logistic Regression on AFR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3747,
     "status": "ok",
     "timestamp": 1569582755976,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "1_64cO8lBmkQ",
    "outputId": "161959a8-7f9d-471d-81dc-8d233b63dced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Scores------\n",
      "train score -> 0.9152428646242472\n",
      "test score -> 0.8945773524720894\n",
      "validation score -> 0.8917910447761194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LR_model.sav']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "clf = LogisticRegression(random_state = 0, solver = 'liblinear').fit(X_train, Y_train)\n",
    "y_val_predict = clf.predict(X_val)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "print(\"----Scores------\")\n",
    "print(\"train score ->\", clf.score(X_train, Y_train))\n",
    "print(\"test score ->\", clf.score(X_test, Y_test))\n",
    "print(\"validation score ->\", clf.score(X_val, Y_val))\n",
    "\n",
    "\n",
    "filename = 'LR_model.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdErqaFdO0KD"
   },
   "source": [
    "### Naive Bayes on AFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1569580032983,
     "user": {
      "displayName": "Shubham Naik",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA5h85SAJBqdfowqcC7_8dtNpEykSCoh8AOH2ouuw=s64",
      "userId": "04070564095250885444"
     },
     "user_tz": -330
    },
    "id": "ba9AtDY1Oy7K",
    "outputId": "d910bd5d-24c4-42fd-c63e-8f12537f3cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Scores------\n",
      "train score -> 0.8996301387797853\n",
      "test score -> 0.8717171717171717\n",
      "validation score -> 0.8695339094003666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "y_val_predict = clf.predict(X_val)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "print(\"----Scores------\")\n",
    "print(\"train score ->\", clf.score(X_train, Y_train))\n",
    "print(\"test score ->\", clf.score(X_test, Y_test))\n",
    "print(\"validation score ->\", clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-idE6OiLQsC5"
   },
   "source": [
    "### SVM on AFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p85iRJcAQwUB"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma = 'auto')\n",
    "clf.fit(X_train, Y_train)\n",
    "y_val_predict = clf.predict(X_val)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "print(\"----Scores------\")\n",
    "print(\"train score ->\", clf.score(X_train, Y_train))\n",
    "print(\"test score ->\", clf.score(X_test, Y_test))\n",
    "print(\"validation score ->\", clf.score(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgdVzcWcxwid"
   },
   "source": [
    "# Conclusions:\n",
    "\n",
    "- Used total of 114,000 reviews from AFR dataset for this exercise.\n",
    "- Balanced the dataset by taking 57k positive and 57K negative reviews.\n",
    "- Converted AFR data into IMDB dataset format.\n",
    "- Used index values of words to encode reviews into vectors.\n",
    "- With single layer of accuarcy I am getting 100% accuracy.\n",
    "- atanh activation performs better then relu in this case.\n",
    "- Used return_sequences=True for 2 layers of LSTM."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SLhaOI_1xwhi",
    "FB7f8IUDxwhl",
    "HHr93n2mxwhp",
    "WlPdbtgPxwht",
    "mJFYvNBkxwhz",
    "sduZORv7xwh6"
   ],
   "machine_shape": "hm",
   "name": "naikshubham_LSTM-on-Amazon-Food-Reviews-Dataset_LSTM - AFR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
